# Домашнее задание к семинару 05 (HW05)

Тема: линейные модели и честный ML-эксперимент (логистическая регрессия, бейзлайн, метрики).

---

## 2. Задание


#### 2.2.1. Общая информация

- Каждая строка – условный клиент банка с набором финансовых и поведенческих признаков.
- Целевая переменная (`target`) – столбец `default`: факт дефолта по кредиту (1 – дефолт, 0 – нет).
- Размер датасета – порядка 3000 наблюдений (строк).
- Доля `default = 1` – около 40% (задача не идеально сбалансирована, но и не экстремально перекошена).

#### 2.2.2. Описание столбцов

В датасете содержатся следующие столбцы (набор может быть немного расширен, но смысл – такой):

- `client_id` – идентификатор клиента (целое число).  
  Используется только как технический ID, в модели его можно не использовать.

- `age` – возраст клиента (целое число, ~21-69 лет).

- `income` – годовой доход клиента (целое число в условных единицах, ~15 000-200 000).

- `years_employed` – стаж работы (количество полных лет, целое число).

- `credit_score` – условный кредитный скоринг (целое число, диапазон примерно 300-850).  
  Чем выше значение, тем «надёжнее» клиент.

- `debt_to_income` – отношение ежемесячных долговых платежей к доходу (вещественное число от 0 до 1).

- `num_credit_cards` – количество кредитных карт (целое число, обычно от 0 до 7).

- `num_late_payments` – количество просрочек платежей за некоторый период (целое число, от 0 и выше).

- `has_mortgage` – флаг наличия ипотеки (0 – нет, 1 – есть).

- `has_car_loan` – флаг наличия автокредита (0 – нет, 1 – есть).

- `savings_balance` – объём сбережений клиента (целое число, от 0 и выше, условные единицы).

- `checking_balance` – баланс на расчетном счёте (целое число, может быть отрицательным).

- `region_risk_score` – условный риск региона проживания клиента (вещественное число 0..1; чем больше, тем рискованнее).

- `phone_calls_to_support_last_3m` – количество обращений клиента в поддержку за последние 3 месяца (целое число).

- `active_loans` – количество активных займов (целое число).

- `customer_tenure_years` – сколько лет клиент обслуживается в этом банке (целое число).

- `default` – **целевой бинарный признак**: факт дефолта по кредиту (0/1).  
  Это **таргет**, который нужно предсказывать.

> Описание признаков даётся для понимания контекста. Это не отменяет необходимости сделать свой минимальный EDA и посмотреть на распределения, баланс классов и т.п.

---

### 2.3. Содержание ноутбука `HW05.ipynb` (основная часть)

В ноутбуке `homeworks/HW05/HW05.ipynb` необходимо выполнить следующие шаги.

#### 2.3.1. Загрузка данных и первичный анализ

1. Импортировать необходимые библиотеки:
   - `pandas` и, при необходимости, `numpy`;
   - модули из `scikit-learn`: `train_test_split`, `DummyClassifier`, `LogisticRegression`, `Pipeline`, `StandardScaler`, метрики (`accuracy_score`, `roc_auc_score` и т.п.);
   - при желании – `matplotlib`/`seaborn` для графиков.

2. Загрузить датасет `S05-hw-dataset.csv` в `pandas.DataFrame` с помощью `pd.read_csv`.

3. Вывести и проанализировать:
   - первые строки датасета (`head()`),
   - информацию о столбцах и типах (`info()`),
   - базовые описательные статистики для числовых признаков (`describe()` или аналог),
   - распределение целевого признака `default` (например, через `value_counts(normalize=True)`).

#### 2.3.2. Подготовка признаков и таргета

1. Выделить матрицу признаков `X` и вектор таргета `y`:
2. При необходимости выполнить простую предобработку


#### 2.3.3. Train/Test-сплит и бейзлайн-модель

1. Разделить данные на обучающую и тестовую выборки
2. Построить **бейзлайн-модель** на основе `DummyClassifier`:
   - например, `strategy="most_frequent"` или `strategy="stratified"`;
   - обучить её на обучающей выборке (`fit(X_train, y_train)`).
3. Оценить бейзлайн по крайней мере по двум метрикам:
   - `accuracy` на тестовой выборке;
   - `ROC-AUC` на тестовой выборке (если используете `predict_proba` или `decision_function`).

#### 2.3.4. Логистическая регрессия и подбор гиперпараметров

1. Построить `Pipeline`, состоящий минимум из:
   - стандартизации признаков (`StandardScaler`);
   - логистической регрессии (`LogisticRegression`).
2. Подобрать параметр регуляризации `C` (и при желании ещё 1-2 параметра) с помощью:
   - простого перебора в цикле по нескольким значениям `C` (например, `[0.01, 0.1, 1.0, 10.0]`).
3. Для лучшей найденной модели посчитать на тестовой выборке:
   - `accuracy`;
   - `ROC-AUC`;
   - по желанию: `precision`, `recall`, `f1`, confusion matrix.

4. (Рекомендуется) Построить хотя бы один график:

   - ROC-кривая **или** PR-кривая (для этого можно использовать функции из `sklearn.metrics` + `matplotlib`).

5. Сохранить хотя бы один график (например, ROC-кривую) в файл в папку `homeworks/HW05/figures/`.

#### 2.3.5. Сравнение бейзлайна и логистической регрессии, текстовые выводы

1. Свести результаты в компактный вид:

   - можно сделать небольшую табличку (например, `pandas.DataFrame`), где по строкам – модели (Dummy vs LogisticRegression), по столбцам – метрики;
   - либо просто аккуратно вывести все значения в текстовом виде.

2. В конце ноутбука написать **краткий текстовый отчёт** (5-10 предложений), в котором:

   - объяснить, чем бейзлайн отличается от логистической регрессии по качеству;
   - указать, насколько сильно выросла (или не выросла) `accuracy` и `ROC-AUC`;
   - при наличии нескольких значений `C` – прокомментировать, как изменение регуляризации влияло на качество;
   - сформулировать 2-3 простых вывода о том, какая модель кажется разумной для этой задачи и почему.

---

